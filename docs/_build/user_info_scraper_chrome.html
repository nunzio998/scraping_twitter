

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>user_info_scraper &mdash; Dcomuentazione Tesi 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="beautifulsoup_analisys" href="beautifulsoup_analisys_chrome.html" />
    <link rel="prev" title="tweet_scraper" href="tweet_scraper_chrome.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Dcomuentazione Tesi
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="DarkWeb_scraper.html">DarkWeb</a></li>
<li class="toctree-l1"><a class="reference internal" href="Discord_scraper.html">Discord</a></li>
<li class="toctree-l1"><a class="reference internal" href="Telegram_scraper.html">Telegram</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="X_scraper.html">X</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="Google_Chrome.html">Google Chrome</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="db_to_csv_x_chrome.html">db_to_csv</a></li>
<li class="toctree-l3"><a class="reference internal" href="drop_data_collection_x_chrome.html">drop_data_collection</a></li>
<li class="toctree-l3"><a class="reference internal" href="related_user_finder_chrome.html">related_user_finder</a></li>
<li class="toctree-l3"><a class="reference internal" href="tweet_scraper_chrome.html">tweet_scraper</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">user_info_scraper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#src.X_scraping.chrome.user_info_scraper.scrape_user_info"><code class="docutils literal notranslate"><span class="pre">scrape_user_info()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="beautifulsoup_analisys_chrome.html">beautifulsoup_analisys</a></li>
<li class="toctree-l3"><a class="reference internal" href="utils_x_chrome.html">utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="deepfake_detection_chrome.html">deepfake detection chrome</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Firefox.html">Firefox</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Dcomuentazione Tesi</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="X_scraper.html">X</a></li>
          <li class="breadcrumb-item"><a href="Google_Chrome.html">Google Chrome</a></li>
      <li class="breadcrumb-item active">user_info_scraper</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/user_info_scraper_chrome.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-src.X_scraping.chrome.user_info_scraper">
<span id="user-info-scraper"></span><h1>user_info_scraper<a class="headerlink" href="#module-src.X_scraping.chrome.user_info_scraper" title="Link to this heading"></a></h1>
<p>Script per l’estrazione automatica delle informazioni di profili utente da X (precedentemente noto come Twitter).</p>
<p>Questo script esegue il login a X, estrae gli utenti target da un database MongoDB contenente dati relativi ai tweet raccolti,
e raccoglie informazioni specifiche su ciascun utente tramite una navigazione automatica su X. Le informazioni raccolte includono
dati come nome utente, biografia, numero di follower, tweet recenti e altre metriche pertinenti.</p>
<p>Le informazioni estratte vengono successivamente salvate in una collection del database MongoDB, denominata <cite>users_info</cite>,
per una successiva analisi.</p>
<p><strong>Funzionalità principali</strong>:</p>
<ol class="arabic">
<li><p><strong>Estrazione degli Utenti Target</strong>: Lo script estrae gli utenti da tutte le collezioni del database MongoDB che contengono dati relativi ai tweet, ad eccezione delle collection <cite>users_info</cite> e <cite>target_groups</cite>. Gli utenti sono identificati tramite il campo <cite>username_tag</cite> presente in ciascun documento. La lista di utenti viene generata evitando duplicati.</p></li>
<li><p><strong>Login a X</strong>: Utilizzando le credenziali memorizzate in un file JSON, lo script effettua il login su X. La sessione di login viene automatizzata tramite il driver Firefox di Selenium in modalità “headless” (senza interfaccia grafica).</p></li>
<li><p><strong>Raccolta delle Informazioni sui Profili</strong>:</p>
<blockquote>
<div><p>Per ciascun utente nella lista di target, lo script:</p>
</div></blockquote>
<ul class="simple">
<li><p>Accede al profilo dell’utente su X.</p></li>
<li><p>Verifica che il profilo esista e che l’account non sia limitato.</p></li>
<li><p>Raccoglie le informazioni pubblicamente visibili sul profilo, tra cui nome utente, bio, numero di follower, tweet recenti e altre statistiche.</p></li>
<li><p>Gestisce automaticamente eventuali account limitati, come nel caso in cui l’account sia stato bloccato temporaneamente.</p></li>
</ul>
</li>
<li><p><strong>Analisi HTML tramite BeautifulSoup</strong>: Una volta che la pagina del profilo utente è stata caricata, lo script utilizza BeautifulSoup per analizzare l’HTML e estrarre le informazioni pertinenti dal contenuto.</p></li>
<li><p><strong>Salvataggio delle Informazioni nel Database</strong>: Le informazioni estratte da ciascun profilo vengono salvate nel database MongoDB nella collection <cite>users_info</cite>, per l’archiviazione e l’analisi futura.</p></li>
<li><p><strong>Gestione degli Errori</strong>: Lo script è progettato per proseguire con la raccolta dei dati anche se un utente non viene trovato, se il profilo è limitato o se si verificano altri errori. In questi casi, il processo non viene interrotto e il sistema continua con il successivo utente.</p></li>
<li><p><strong>Chiusura delle Risorse</strong>: Alla fine del processo di scraping, il driver di Selenium viene correttamente chiuso e la connessione al database MongoDB viene terminata.</p></li>
</ol>
<p><strong>Autore</strong>: Francesco Pinsone.</p>
<dl class="py function">
<dt class="sig sig-object py" id="src.X_scraping.chrome.user_info_scraper.scrape_user_info">
<span class="sig-prename descclassname"><span class="pre">src.X_scraping.chrome.user_info_scraper.</span></span><span class="sig-name descname"><span class="pre">scrape_user_info</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/src/X_scraping/chrome/user_info_scraper.html#scrape_user_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#src.X_scraping.chrome.user_info_scraper.scrape_user_info" title="Link to this definition"></a></dt>
<dd><p>Funzione che automatizza la raccolta delle informazioni sui profili utente da X (precedentemente noto come Twitter).
Lo script esegue il login su X, esegue la ricerca di utenti target estratti da tutte le collezioni di tweet nel database
e raccoglie le informazioni associate a ciascun utente. Le informazioni estratte vengono poi salvate nel database MongoDB,
nella collection ‘users_info’. Questo processo permette di ottenere dettagli rilevanti sugli utenti coinvolti, come il loro
nome utente, bio, numero di follower, post recenti, e altre informazioni pertinenti.</p>
<p><strong>Funzionamento del Processo</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Connessione al Database</strong>: La funzione si connette al database MongoDB per estrarre una lista di utenti target da tutte le collezioni che contengono dati relativi ai tweet salvati (eccetto le collection <cite>users_info</cite> e <cite>target_groups</cite>). Gli utenti vengono identificati tramite il campo <cite>username_tag</cite>.</p></li>
<li><p><strong>Creazione della Lista di Target</strong>: Lo script attraversa tutte le collezioni del database, estraendo il campo <cite>username_tag</cite> da ciascun documento che contiene informazioni sui tweet. Gli username vengono aggiunti a una lista, evitando duplicati.</p></li>
<li><p><strong>Preparazione per l’Automazione del Browser</strong>: Utilizzando Selenium e il driver Firefox in modalità “headless” (senza interfaccia grafica), viene configurato il browser per simulare la navigazione su X e raccogliere informazioni sui profili utente.</p></li>
<li><p><strong>Login su X</strong>: Dopo aver configurato il browser, la funzione effettua il login su X utilizzando le credenziali memorizzate in un file JSON.</p></li>
<li><p><strong>Raccolta delle Informazioni sugli Utenti</strong>:</p>
<ul class="simple">
<li><p>Per ciascun utente nella lista di target, lo script esegue una ricerca sul suo profilo su X.</p></li>
<li><p>Se l’utente esiste, lo script raccoglie le informazioni disponibili sul suo profilo, come il nome, la bio, i follower, i tweet recenti, e altre metriche.</p></li>
<li><p>Se l’utente è limitato temporaneamente (ad esempio, se il profilo è stato bloccato per qualche motivo), lo script gestisce automaticamente questa situazione e prosegue.</p></li>
</ul>
</li>
<li><p><strong>Analisi con BeautifulSoup</strong>: Una volta che il contenuto HTML del profilo dell’utente è stato caricato, viene passato a BeautifulSoup per l’analisi e l’estrazione delle informazioni rilevanti. Questo permette di strutturare i dati in un formato utile per il salvataggio nel database.</p></li>
<li><p><strong>Salvataggio nel Database</strong>: Le informazioni estratte da ciascun profilo utente vengono salvate nella collection <cite>users_info</cite> del database MongoDB.</p></li>
<li><p><strong>Gestione degli Errori</strong>: Se un utente non viene trovato o se si verificano errori durante la raccolta dei dati (ad esempio, l’utente ha un profilo limitato o non è accessibile), lo script continua automaticamente con il prossimo utente, senza interrompere l’esecuzione.</p></li>
<li><p><strong>Chiusura delle Risorse</strong>: Al termine dell’operazione di scraping, il driver di Selenium viene chiuso correttamente e la connessione al database viene terminata.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Nessun valore restituito. Le informazioni sugli utenti vengono salvate direttamente nel database.</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tweet_scraper_chrome.html" class="btn btn-neutral float-left" title="tweet_scraper" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="beautifulsoup_analisys_chrome.html" class="btn btn-neutral float-right" title="beautifulsoup_analisys" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Francesco Pinsone.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>