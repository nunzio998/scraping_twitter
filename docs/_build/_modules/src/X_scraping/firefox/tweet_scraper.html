

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>src.X_scraping.firefox.tweet_scraper &mdash; Documentazione Tesi 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=8d563738"></script>
      <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            Documentazione Tesi
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../DarkWeb_scraper.html">DarkWeb</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../Discord_scraper.html">Discord</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../Telegram_scraper.html">Telegram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../X_scraper.html">X</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Documentazione Tesi</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">src.X_scraping.firefox.tweet_scraper</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for src.X_scraping.firefox.tweet_scraper</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Questo script automatizza il processo di scraping di tweet da X (precedentemente noto come Twitter) per raccogliere informazioni</span>
<span class="sd">relativi a gruppi hacker, come indicato in un report sulla cybersecurity del 2024. L&#39;obiettivo principale è eseguire una</span>
<span class="sd">ricerca su X per estrarre i tweet pertinenti a specifici gruppi hacker, raccogliendo vari dettagli come autore, contenuto, URL,</span>
<span class="sd">video, immagini, e il gruppo hacker di riferimento. Tutti i dati raccolti vengono quindi salvati nel database MongoDB per un</span>
<span class="sd">eventuale utilizzo futuro.</span>

<span class="sd">**Funzionamento del Processo**:\n</span>
<span class="sd">1. **Connessione al Database**: Lo script si connette a un database MongoDB per recuperare i gruppi target (gruppi hacker) definiti nella collection `target_groups`. Questi gruppi sono utilizzati come base per la ricerca dei tweet.</span>

<span class="sd">2. **Preparazione per l&#39;Automazione del Browser**: Utilizzando Selenium e il driver Firefox in modalità &quot;headless&quot; (senza interfaccia grafica), viene configurato il browser per l&#39;automazione della navigazione su X. Questo approccio consente di simulare l&#39;interazione umana con il sito in modo che lo scraping possa essere effettuato automaticamente.</span>

<span class="sd">3. **Login su X**: Lo script esegue un login automatizzato a X utilizzando le credenziali memorizzate in un file JSON. La parte di login è manuale attraverso l&#39;uso di un&#39;apposita funzione, per garantire la sicurezza delle credenziali.</span>

<span class="sd">4. **Costruzione della Ricerca**: Per ogni gruppo target, viene costruito un URL di ricerca personalizzato. Questo URL filtra i tweet relativi al gruppo target, utilizzando le parole chiave scelte e limitando i risultati a quelli pubblicati tra la data dell&#39;ultimo aggiornamento e quella odierna.</span>

<span class="sd">5. **Caricamento e Raccolta dei Tweet**:</span>
<span class="sd">   - Lo script naviga nella pagina di ricerca su X, dove i tweet vengono caricati dinamicamente.</span>
<span class="sd">   - Per garantire di raccogliere tutti i tweet disponibili, viene eseguita una scrollata continua della pagina, caricando tweet aggiuntivi ogni volta che la pagina si aggiorna.</span>

<span class="sd">6. **Estrazione e Analisi del Contenuto**:</span>
<span class="sd">   - Una volta caricati i tweet, l&#39;HTML della pagina viene estratto utilizzando Selenium.</span>
<span class="sd">   - Il contenuto viene quindi analizzato tramite BeautifulSoup, che struttura e filtra i tweet in modo che possano essere facilmente utilizzati e salvati nel database.</span>

<span class="sd">7. **Salvataggio dei Dati nel Database**: Le informazioni estratte dai tweet (come autore, contenuto, URL, immagini, video e gruppo hacker di riferimento) vengono parsate e salvate nel database MongoDB per una successiva consultazione o analisi.</span>

<span class="sd">8. **Gestione degli Aggiornamenti**: Alla fine di ogni esecuzione, lo script aggiorna la data dell&#39;ultimo aggiornamento nel database, in modo che nelle esecuzioni future lo script possa raccogliere solo i tweet nuovi, risparmiando tempo e risorse.</span>

<span class="sd">9. **Gestione degli Errori**: Se non vengono trovati risultati per un gruppo target o se si verificano problemi nel caricare una pagina (ad esempio, a causa di un errore di rete o di un timeout), lo script continua automaticamente con il gruppo successivo, senza interrompere l&#39;intero processo di scraping.</span>

<span class="sd">10. **Chiusura delle Risorse**: Alla fine del processo, il driver Selenium viene chiuso correttamente, e la connessione al database MongoDB viene terminata, liberando risorse e chiudendo tutte le connessioni attive.</span>

<span class="sd">**Obiettivo**:\n</span>
<span class="sd">Il principale scopo di questo script è raccogliere informazioni utili dai tweet pubblici relativi ai gruppi hacker, al fine di monitorare le attività dei gruppi di interesse in un contesto di sicurezza informatica. Ogni esecuzione dello script consente di ottenere dati aggiornati e pertinenti, che possono essere analizzati per osservare eventuali tendenze o comportamenti sospetti.</span>

<span class="sd">**Autore**: Francesco Pinsone.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">from</span> <span class="nn">selenium.common.exceptions</span> <span class="kn">import</span> <span class="n">TimeoutException</span>
<span class="kn">from</span> <span class="nn">selenium.webdriver.common.by</span> <span class="kn">import</span> <span class="n">By</span>
<span class="kn">from</span> <span class="nn">selenium.webdriver.firefox.service</span> <span class="kn">import</span> <span class="n">Service</span>
<span class="kn">from</span> <span class="nn">selenium.webdriver.firefox.options</span> <span class="kn">import</span> <span class="n">Options</span>
<span class="kn">from</span> <span class="nn">selenium.webdriver.support</span> <span class="kn">import</span> <span class="n">expected_conditions</span> <span class="k">as</span> <span class="n">EC</span>
<span class="kn">from</span> <span class="nn">selenium.webdriver.support.ui</span> <span class="kn">import</span> <span class="n">WebDriverWait</span>
<span class="kn">from</span> <span class="nn">src.X_scraping.firefox.utils.utils</span> <span class="kn">import</span> <span class="n">primary_keywords</span><span class="p">,</span> <span class="n">secondary_keywords</span><span class="p">,</span> <span class="n">read_json</span><span class="p">,</span> <span class="n">connect_to_mongo</span><span class="p">,</span> \
    <span class="n">connect_to_mongo_collection</span><span class="p">,</span> <span class="n">disconnect_to_mongo</span><span class="p">,</span> <span class="n">parse_and_save</span><span class="p">,</span> <span class="n">x_login</span>
<span class="kn">from</span> <span class="nn">src.X_scraping.firefox.beautifulsoup_analisys</span> <span class="kn">import</span> <span class="n">analisys_with_beautifulsoup</span>


<div class="viewcode-block" id="scrape_tweets">
<a class="viewcode-back" href="../../../../tweet_scraper_firefox.html#src.X_scraping.firefox.tweet_scraper.scrape_tweets">[docs]</a>
<span class="k">def</span> <span class="nf">scrape_tweets</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Funzione che automatizza la raccolta dei tweet da X (precedentemente noto come Twitter) per gruppi target predefiniti.</span>
<span class="sd">    Il processo comprende il login su X, la ricerca di tweet relativi a ciascun gruppo, e l&#39;estrazione delle informazioni</span>
<span class="sd">    pertinenti da ciascun tweet. Le informazioni estratte vengono quindi salvate nel database MongoDB.</span>

<span class="sd">    **Funzionamento**:\n</span>
<span class="sd">    1. **Connessione al Database**: La funzione inizia con la connessione al database MongoDB, dove vengono recuperati i gruppi target dalla collection &quot;target_groups&quot;. Ogni gruppo target corrisponde a una ricerca di tweet specifica su X.</span>

<span class="sd">    2. **Configurazione del Browser**: Utilizzando Selenium e il driver Firefox in modalità &quot;headless&quot; (senza interfaccia grafica), viene configurato il browser per interagire automaticamente con il sito X.</span>

<span class="sd">    3. **Login su X**: Dopo aver configurato il browser, la funzione esegue il login su X utilizzando le credenziali fornite tramite un file JSON.</span>

<span class="sd">    4. **Creazione della Ricerca**: Per ogni gruppo target:\n</span>
<span class="sd">       - Viene costruito un URL di ricerca personalizzato che include la data odierna e la data dell&#39;ultimo aggiornamento per filtrare i tweet.\n</span>
<span class="sd">       - Viene eseguita una ricerca su X per ottenere i tweet relativi a quel gruppo, limitando i risultati a quelli pubblicati tra la data dell&#39;ultimo aggiornamento e quella odierna.\n</span>

<span class="sd">    5. **Raccolta dei Tweet**: Una volta caricata la pagina con i risultati della ricerca:\n</span>
<span class="sd">       - Viene eseguita una scrollata della pagina per caricare i tweet aggiuntivi.\n</span>
<span class="sd">       - L&#39;HTML della pagina viene estratto e analizzato con BeautifulSoup, che filtra e organizza i tweet trovati.\n</span>

<span class="sd">    6. **Estrazione e Salvataggio delle Informazioni**: I tweet estratti vengono parsati in una struttura utile, quindi vengono salvati nel database MongoDB.</span>

<span class="sd">    7. **Aggiornamento della Data di Riferimento**: Una volta completata l&#39;operazione di scraping, la data dell&#39;ultimo aggiornamento viene registrata nel database per essere utilizzata nelle future esecuzioni dello script.</span>

<span class="sd">    8. **Gestione degli Errori**: Se non vengono trovati risultati per un gruppo target o se si verificano errori durante il caricamento della pagina, lo script continua con il gruppo successivo senza interrompere l&#39;esecuzione.</span>

<span class="sd">    Alla fine, il driver di Selenium viene chiuso e la connessione al database viene terminata.</span>

<span class="sd">    :return: Nessun valore ritornato. Le informazioni vengono salvate nel database.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Configuro il logger</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>  <span class="c1"># Imposto il livello minimo di log</span>
                        <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> - </span><span class="si">%(levelname)s</span><span class="s1"> - </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># Formato del log</span>

    <span class="c1"># Leggo file con credenziali</span>
    <span class="n">credentials</span> <span class="o">=</span> <span class="n">read_json</span><span class="p">(</span><span class="s2">&quot;utils/conf.json&quot;</span><span class="p">)</span>

    <span class="c1"># Connessione al DB</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">connect_to_mongo</span><span class="p">()</span>

    <span class="c1"># Estrapolazione della lista di target su cui far partire la ricerca</span>
    <span class="k">if</span> <span class="n">credentials</span><span class="p">[</span><span class="s1">&#39;group_search&#39;</span><span class="p">]:</span>
        <span class="n">targets_collection</span> <span class="o">=</span> <span class="n">connect_to_mongo_collection</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="s2">&quot;target_groups&quot;</span><span class="p">)</span>
        <span class="n">documents</span> <span class="o">=</span> <span class="n">targets_collection</span><span class="o">.</span><span class="n">find</span><span class="p">()</span>
        <span class="n">target_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">doc</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span> <span class="c1"># Sostituisco gli spazi con underscore per semplificare la query di ricerca</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">target_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">credentials</span><span class="p">[</span><span class="s1">&#39;cve&#39;</span><span class="p">]]</span>

    <span class="c1"># Configura opzioni del browser</span>
    <span class="n">firefox_options</span> <span class="o">=</span> <span class="n">Options</span><span class="p">()</span>
    <span class="n">firefox_options</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--headless&quot;</span><span class="p">)</span>

    <span class="c1"># Geckodriver</span>
    <span class="n">service</span> <span class="o">=</span> <span class="n">Service</span><span class="p">(</span><span class="s1">&#39;driver/geckodriver&#39;</span><span class="p">)</span>

    <span class="c1"># Inizializzo driver  Firefox</span>
    <span class="n">driver</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Firefox</span><span class="p">(</span><span class="n">service</span><span class="o">=</span><span class="n">service</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">firefox_options</span><span class="p">)</span>
    <span class="c1"># driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))</span>

    <span class="c1"># Carico la pagina di login di X</span>
    <span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://www.twitter.com/login&#39;</span><span class="p">)</span>

    <span class="c1"># Imposto un&#39;attesa esplicita di massimo 60 secondi</span>
    <span class="n">wait_login</span> <span class="o">=</span> <span class="n">WebDriverWait</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>

    <span class="c1"># Aspetto che un campo di ricerca con ID &#39;search-input&#39; sia visibile</span>
    <span class="n">search_input_login</span> <span class="o">=</span> <span class="n">wait_login</span><span class="o">.</span><span class="n">until</span><span class="p">(</span><span class="n">EC</span><span class="o">.</span><span class="n">visibility_of_element_located</span><span class="p">((</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span> <span class="s1">&#39;/html/body/div/div/div/div[1]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[4]/label/div/div[2]/div/input&#39;</span><span class="p">)))</span>

    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Effettuo il login a X</span>
    <span class="n">x_login</span><span class="p">(</span><span class="n">credentials</span><span class="p">,</span> <span class="n">driver</span><span class="p">)</span>

    <span class="c1"># Imposto la data odierna e ottengo l&#39;ultima data di aggiornamento</span>
    <span class="n">today</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">today</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">coll</span> <span class="o">=</span> <span class="n">connect_to_mongo_collection</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="s2">&quot;last_update&quot;</span><span class="p">)</span>

    <span class="n">last_update</span> <span class="o">=</span> <span class="n">coll</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;01&quot;</span><span class="p">})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;last_update&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">target_list</span><span class="p">:</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> in lavorazione..&quot;</span><span class="p">)</span>

        <span class="n">target_collection</span> <span class="o">=</span> <span class="n">connect_to_mongo_collection</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="c1"># keyword1 = random.choice(primary_keywords)</span>
        <span class="c1"># keyword2 = random.choice(secondary_keywords)</span>
        <span class="c1">#</span>
        <span class="c1"># search_url = f&quot;https://x.com/search?q={group}%20{keyword1}%20{keyword2}%20lang%3Aen%20-filter%3Alinks%20-filter%3Areplies&amp;src=typed_query&quot;</span>

        <span class="n">search_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;https://x.com/search?q=</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">%20until%3A</span><span class="si">{</span><span class="n">today</span><span class="si">}</span><span class="s2">%20since%3A</span><span class="si">{</span><span class="n">last_update</span><span class="si">}</span><span class="s2">%20-filter%3Areplies&amp;src=typed_query&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">search_url</span><span class="p">)</span>

            <span class="c1"># Attendo caricamento pagina</span>
            <span class="n">wait_tweets</span> <span class="o">=</span> <span class="n">WebDriverWait</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>

            <span class="c1"># Aspettare che un elemento indicativo del completo caricamento della pagina sia visibile</span>
            <span class="n">search_tweets</span> <span class="o">=</span> <span class="n">wait_tweets</span><span class="o">.</span><span class="n">until</span><span class="p">(</span><span class="n">EC</span><span class="o">.</span><span class="n">visibility_of_element_located</span><span class="p">((</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span> <span class="s1">&#39;/html/body/div[1]/div/div/div[2]/main/div/div/div/div[1]/div/div[3]/section/div&#39;</span><span class="p">)))</span>
        <span class="k">except</span> <span class="n">TimeoutException</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Nessun risultato per </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">..&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># Scorri la pagina verso il basso per caricare più tweet</span>
        <span class="n">last_height</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="s2">&quot;return document.body.scrollHeight&quot;</span><span class="p">)</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">driver</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="s2">&quot;window.scrollTo(0, document.body.scrollHeight);&quot;</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>  <span class="c1"># Attesa casuale nel tentativo di simulare il comportamento umano</span>
            <span class="n">new_height</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="s2">&quot;return document.body.scrollHeight&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_height</span> <span class="o">==</span> <span class="n">last_height</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">last_height</span> <span class="o">=</span> <span class="n">new_height</span>

            <span class="c1"># Estraggo HTML pagina con BeautifulSoup e lo stampo</span>
            <span class="n">html_content</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">page_source</span>
            <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html_content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">analisys_with_beautifulsoup</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">prettify</span><span class="p">())</span>

            <span class="c1"># Divido le info in post e le salvo nel database</span>
            <span class="n">parse_and_save</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">target_collection</span><span class="p">)</span>

    <span class="c1"># Se non sto cercando dati relativi alle CVE, bensi sto ricercando informazioni sui gruppi hacker, aggiorno la data di ultimo aggiornamento</span>
    <span class="k">if</span> <span class="n">credentials</span><span class="p">[</span><span class="s1">&#39;group_search&#39;</span><span class="p">]:</span>
        <span class="n">coll</span> <span class="o">=</span> <span class="n">connect_to_mongo_collection</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="s2">&quot;last_update&quot;</span><span class="p">)</span>
        <span class="n">coll</span><span class="o">.</span><span class="n">update_one</span><span class="p">({</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="s2">&quot;01&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;$set&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;last_update&quot;</span><span class="p">:</span> <span class="n">today</span><span class="p">}})</span>

    <span class="n">disconnect_to_mongo</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
    <span class="n">driver</span><span class="o">.</span><span class="n">quit</span><span class="p">()</span></div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">scrape_tweets</span><span class="p">()</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Francesco Pinsone.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>